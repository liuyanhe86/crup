{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "torch.set_printoptions(profile='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([3])\n",
      "tensor([[6., 6., 6.],\n",
      "        [6., 6., 6.]])\n",
      "tensor([ 5.1962, 10.3923])\n",
      "tensor(7.7942)\n",
      "tensor(6.7500)\n",
      "tensor([0.1353, 0.0003])\n",
      "tensor(0.1357)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([6., 6., 6.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proto = torch.Tensor([[1,2,3]])\n",
    "print(proto.size())\n",
    "print(proto.squeeze(0).shape)\n",
    "Z_p = torch.Tensor([[4,5,6], [7,8,9]])\n",
    "Z_c = torch.Tensor([[10,11,12], [13,14,15]])\n",
    "delta = Z_c - Z_p\n",
    "print(delta)\n",
    "dist = torch.sqrt(torch.sum(torch.pow(Z_p - proto, 2), dim=1))\n",
    "print(dist)\n",
    "dist_mean = torch.mean(dist)\n",
    "print(dist_mean)\n",
    "dist_variance = torch.mean(torch.pow(dist - dist_mean, 2))\n",
    "print(dist_variance)\n",
    "w = torch.exp(-torch.pow(dist, 2) / (2 * dist_variance))\n",
    "print(w)\n",
    "W = torch.sum(w)\n",
    "print(W)\n",
    "torch.sum(torch.unsqueeze(w, 1) * delta, dim=0) / W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3480, -0.7114,  0.0283,  0.5568,  0.2489])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = torch.randn(5)\n",
    "F.normalize(embedding, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.4204e-03,  6.4207e-01,  1.4702e-01, -1.3592e-02,  7.5227e-01],\n",
       "        [ 3.0482e-01, -5.1897e-01, -7.9719e-01,  1.8418e-02, -4.3599e-02],\n",
       "        [-4.8780e-02,  2.9550e-01, -2.3958e-01, -9.2353e-01, -4.6353e-05],\n",
       "        [-2.8724e-02,  2.1884e-01,  8.4716e-01,  3.7832e-01,  3.0080e-01],\n",
       "        [ 2.5956e-01,  6.6577e-01, -4.3384e-01,  4.8069e-01,  2.6475e-01],\n",
       "        [ 5.1806e-01, -2.4194e-01, -6.9662e-01, -4.6739e-02,  4.3084e-01],\n",
       "        [-8.1449e-01, -3.7669e-01, -8.1611e-02, -3.4818e-01, -2.5850e-01],\n",
       "        [-6.0941e-01,  2.6994e-01,  4.9418e-01, -5.5813e-01, -4.9405e-03],\n",
       "        [ 1.0311e-01, -6.7575e-01, -5.0741e-01, -4.7478e-02, -5.2250e-01],\n",
       "        [-9.3107e-02, -2.9841e-01, -8.5853e-01,  3.9782e-01,  8.3371e-02]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = F.normalize(torch.randn(10,5), dim=1)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.Tensor([0,1,1,0,0,2,2,0,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[100.0000, -48.5429,  16.7340,  48.6387,  55.4649,   6.3653, -43.8359,\n",
       "          25.3762, -90.1557, -25.9919],\n",
       "        [-48.5429, 100.0000,   0.5757, -80.3821,   7.6767,  81.9165,   1.7140,\n",
       "         -72.9874,  80.8538,  81.4591],\n",
       "        [ 16.7340,   0.5757, 100.0000, -48.6294, -15.5924,  11.3274,  26.9539,\n",
       "          50.6548,  -3.9278, -24.5351],\n",
       "        [ 48.6387, -80.3821, -48.6294, 100.0000,   3.2195, -54.6056, -33.7658,\n",
       "          28.2592, -75.5831, -61.4363],\n",
       "        [ 55.4649,   7.6767, -15.5924,   3.2195, 100.0000,  36.7210, -66.2602,\n",
       "         -46.2450, -36.4151,  36.2922],\n",
       "        [  6.3653,  81.9165,  11.3274, -54.6056,  36.7210, 100.0000, -36.9058,\n",
       "         -70.1317,  34.7486,  63.9355],\n",
       "        [-43.8359,   1.7140,  26.9539, -33.7658, -66.2602, -36.9058, 100.0000,\n",
       "          54.9950,  36.3576,   9.8246],\n",
       "        [ 25.3762, -72.9874,  50.6548,  28.2592, -46.2450, -70.1317,  54.9950,\n",
       "         100.0000, -46.6925, -67.0527],\n",
       "        [-90.1557,  80.8538,  -3.9278, -75.5831, -36.4151,  34.7486,  36.3576,\n",
       "         -46.6925, 100.0000,  56.5232],\n",
       "        [-25.9919,  81.4591, -24.5351, -61.4363,  36.2922,  63.9355,   9.8246,\n",
       "         -67.0527,  56.5232, 100.0000]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_product_tempered = torch.mm(batch, batch.T) / temperature  # z_i \\dot z_j / \\tau\n",
    "dot_product_tempered.size()  # [dim, dim](10,10)\n",
    "dot_product_tempered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([[100.0000],\n",
      "        [100.0000],\n",
      "        [100.0000],\n",
      "        [100.0000],\n",
      "        [100.0000],\n",
      "        [100.0000],\n",
      "        [100.0000],\n",
      "        [100.0000],\n",
      "        [100.0000],\n",
      "        [100.0000]]),\n",
      "indices=tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6],\n",
      "        [7],\n",
      "        [8],\n",
      "        [9]]))\n",
      "tensor([[   0.0000, -148.5429,  -83.2660,  -51.3613,  -44.5351,  -93.6347,\n",
      "         -143.8359,  -74.6238, -190.1557, -125.9919],\n",
      "        [-148.5429,    0.0000,  -99.4243, -180.3821,  -92.3233,  -18.0835,\n",
      "          -98.2860, -172.9874,  -19.1462,  -18.5409],\n",
      "        [ -83.2660,  -99.4243,    0.0000, -148.6294, -115.5924,  -88.6726,\n",
      "          -73.0461,  -49.3452, -103.9278, -124.5350],\n",
      "        [ -51.3613, -180.3821, -148.6294,    0.0000,  -96.7805, -154.6056,\n",
      "         -133.7658,  -71.7408, -175.5831, -161.4363],\n",
      "        [ -44.5351,  -92.3233, -115.5924,  -96.7805,    0.0000,  -63.2790,\n",
      "         -166.2602, -146.2450, -136.4151,  -63.7078],\n",
      "        [ -93.6347,  -18.0835,  -88.6726, -154.6056,  -63.2790,    0.0000,\n",
      "         -136.9058, -170.1317,  -65.2514,  -36.0645],\n",
      "        [-143.8359,  -98.2860,  -73.0461, -133.7658, -166.2602, -136.9058,\n",
      "            0.0000,  -45.0050,  -63.6424,  -90.1754],\n",
      "        [ -74.6238, -172.9874,  -49.3452,  -71.7408, -146.2450, -170.1317,\n",
      "          -45.0050,    0.0000, -146.6925, -167.0527],\n",
      "        [-190.1557,  -19.1462, -103.9279, -175.5831, -136.4151,  -65.2514,\n",
      "          -63.6424, -146.6925,    0.0000,  -43.4768],\n",
      "        [-125.9919,  -18.5409, -124.5351, -161.4363,  -63.7078,  -36.0645,\n",
      "          -90.1754, -167.0527,  -43.4768,    0.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05],\n",
       "        [1.0000e-05, 1.0000e+00, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0014e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0005e-05, 1.0009e-05],\n",
       "        [1.0000e-05, 1.0000e-05, 1.0000e+00, 1.0000e-05, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05],\n",
       "        [1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e+00, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05],\n",
       "        [1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e+00, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05],\n",
       "        [1.0000e-05, 1.0014e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e+00,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05],\n",
       "        [1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e+00, 1.0000e-05, 1.0000e-05, 1.0000e-05],\n",
       "        [1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e+00, 1.0000e-05, 1.0000e-05],\n",
       "        [1.0000e-05, 1.0005e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e+00, 1.0000e-05],\n",
       "        [1.0000e-05, 1.0009e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e-05,\n",
       "         1.0000e-05, 1.0000e-05, 1.0000e-05, 1.0000e+00]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ele = torch.max(dot_product_tempered, dim=1, keepdim=True)\n",
    "print(max_ele)\n",
    "dot_product_tempered = dot_product_tempered - max_ele[0]\n",
    "print(dot_product_tempered)\n",
    "exp_dot_tempered = (\n",
    "    torch.exp(dot_product_tempered) \n",
    "    + 1e-5\n",
    ")  # exp(z_i \\dot z_j / \\tau)，每一行代表和每个其他嵌入的点积\n",
    "exp_dot_tempered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True, False, False,  True,  True, False, False,  True, False, False],\n",
      "        [False,  True,  True, False, False, False, False, False, False, False],\n",
      "        [False,  True,  True, False, False, False, False, False, False, False],\n",
      "        [ True, False, False,  True,  True, False, False,  True, False, False],\n",
      "        [ True, False, False,  True,  True, False, False,  True, False, False],\n",
      "        [False, False, False, False, False,  True,  True, False, False, False],\n",
      "        [False, False, False, False, False,  True,  True, False, False, False],\n",
      "        [ True, False, False,  True,  True, False, False,  True, False, False],\n",
      "        [False, False, False, False, False, False, False, False,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False,  True,  True]])\n",
      "tensor([[0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 分母是z_i与batch中其他嵌入的点积，因此要屏蔽掉exp_dot_tempered中自己与自己相乘的部分，即对角线上的取值\n",
    "unsqeezed_labels = labels.unsqueeze(1)  # [[0],[1],[1],[0],[0],[2],[2],[0],[3],[3]]\n",
    "repeated_labels = unsqeezed_labels.repeat(1, labels.shape[0])  # 每一行都是batch_size长的全为对应的样本的标签的向量\n",
    "mask_similar_class = (repeated_labels == labels)\n",
    "print(mask_similar_class)\n",
    "mask_anchor_out = (1 - torch.eye(exp_dot_tempered.shape[0]))  # 对角线为0其他全为1的batch_size * batch_size的张量\n",
    "print(mask_anchor_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 1., 1., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 1., 0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_combined = mask_similar_class * mask_anchor_out\n",
    "mask_combined # 每个样本在batch中相同样本的其他样本对应的位置为1，不同的为0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 1., 1., 3., 3., 1., 1., 3., 1., 1.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardinality_per_samples = torch.sum(mask_combined, dim=1)\n",
    "cardinality_per_samples  # batch中每个样本的与他标签相同的其他样本的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.0289e-05],\n",
      "        [1.3500e-04],\n",
      "        [1.3500e-04],\n",
      "        [9.0001e-05],\n",
      "        [9.0289e-05],\n",
      "        [9.0000e-05],\n",
      "        [9.0001e-05],\n",
      "        [9.0000e-05],\n",
      "        [9.0000e-05],\n",
      "        [9.0000e-05]])\n",
      "tensor([[-9.3125,  2.2004,  2.2004,  2.2004,  2.1720,  2.2004,  2.2004,  2.2004,\n",
      "          2.2004,  2.2004],\n",
      "        [ 2.6027, -8.9102,  0.8979,  2.6027,  2.6027,  2.6027,  2.6027,  2.6027,\n",
      "          2.6027,  2.6027],\n",
      "        [ 2.6027,  0.8979, -8.9102,  2.6027,  2.6027,  2.6027,  2.6027,  2.6027,\n",
      "          2.6027,  2.6027],\n",
      "        [ 2.1972,  2.1972,  2.1972, -9.3157,  2.1972,  2.1972,  2.1972,  2.1972,\n",
      "          2.1972,  2.1972],\n",
      "        [ 2.1720,  2.2004,  2.2004,  2.2004, -9.3125,  2.2004,  2.2004,  2.2004,\n",
      "          2.2004,  2.2004],\n",
      "        [ 2.1972,  2.1972,  2.1972,  2.1972,  2.1972, -9.3157,  2.1972,  2.1972,\n",
      "          2.1972,  2.1972],\n",
      "        [ 2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972, -9.3157,  2.1972,\n",
      "          2.1972,  2.1972],\n",
      "        [ 2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972, -9.3157,\n",
      "          2.1972,  2.1972],\n",
      "        [ 2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972,\n",
      "         -9.3157,  2.1972],\n",
      "        [ 2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972,  2.1972,\n",
      "          2.1972, -9.3157]])\n"
     ]
    }
   ],
   "source": [
    "fenmu = torch.sum(exp_dot_tempered * mask_anchor_out, dim=1, keepdim=True)\n",
    "print(fenmu)\n",
    "log_prob = -torch.log(exp_dot_tempered / fenmu)\n",
    "print(log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0000, 0.0000, 0.0000, 2.2004, 2.1720, 0.0000, 0.0000, 2.2004, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, -0.0000, 0.8979, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.8979, -0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [2.1972, 0.0000, 0.0000, -0.0000, 2.1972, 0.0000, 0.0000, 2.1972, 0.0000,\n",
      "         0.0000],\n",
      "        [2.1720, 0.0000, 0.0000, 2.2004, -0.0000, 0.0000, 0.0000, 2.2004, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.0000, 2.1972, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.1972, -0.0000, 0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [2.1972, 0.0000, 0.0000, 2.1972, 2.1972, 0.0000, 0.0000, -0.0000, 0.0000,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, -0.0000,\n",
      "         2.1972],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.1972,\n",
      "         -0.0000]])\n",
      "tensor([2.1909, 0.8979, 0.8979, 2.1972, 2.1909, 2.1972, 2.1972, 2.1972, 2.1972,\n",
      "        2.1972])\n",
      "tensor(19.3610)\n"
     ]
    }
   ],
   "source": [
    "log = log_prob * mask_combined\n",
    "print(log)\n",
    "supervised_contrastive_loss_per_sample = torch.sum(log, dim=1) / cardinality_per_samples\n",
    "print(supervised_contrastive_loss_per_sample)\n",
    "supervised_contrastive_loss = torch.sum(supervised_contrastive_loss_per_sample)\n",
    "print(supervised_contrastive_loss)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3f8f18320cc0d9e782967693d965b6f1abb68e26a34d146b737af38164bc8375"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
